{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/karinahou/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import matplotlib\n",
    "import nltk\n",
    "#from nltk import stopwords\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "  \n",
    "# importing all necessery modules for word clouds\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_reviews = pd.read_csv(\"../Data/yelp_review.csv\")\n",
    "yelp_business = pd.read_csv(\"../Data/yelp_business.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vkVSCC7xljjrAI4UGfnKEQ</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>AEx2SYEUJmTxVVB18LlCwA</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Super simple place but amazing nonetheless. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n6QzIUObkYshz4dz2QRJTw</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>VR6GpWIda3SfvPC-lg9H3w</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Small unassuming place that changes their menu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MV3CcKScW05u5LVfF6ok0g</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>CKC0-MOWMqoeWf6s-szl8g</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Lester's is located in a beautiful neighborhoo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IXvOzsEMYtiJI0CARmj77Q</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>ACFtxLv8pGrrxMm6EgjreA</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Love coming here. Yes the place always needs t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L_9BTb55X0GDtThi6GlZ6w</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>s2I_Ni76bjJNK9yG60iD-Q</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Had their chocolate almond croissant and it wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  vkVSCC7xljjrAI4UGfnKEQ  bv2nCi5Qv5vroFiqKGopiw  AEx2SYEUJmTxVVB18LlCwA   \n",
       "1  n6QzIUObkYshz4dz2QRJTw  bv2nCi5Qv5vroFiqKGopiw  VR6GpWIda3SfvPC-lg9H3w   \n",
       "2  MV3CcKScW05u5LVfF6ok0g  bv2nCi5Qv5vroFiqKGopiw  CKC0-MOWMqoeWf6s-szl8g   \n",
       "3  IXvOzsEMYtiJI0CARmj77Q  bv2nCi5Qv5vroFiqKGopiw  ACFtxLv8pGrrxMm6EgjreA   \n",
       "4  L_9BTb55X0GDtThi6GlZ6w  bv2nCi5Qv5vroFiqKGopiw  s2I_Ni76bjJNK9yG60iD-Q   \n",
       "\n",
       "   stars        date                                               text  \\\n",
       "0      5  2016-05-28  Super simple place but amazing nonetheless. It...   \n",
       "1      5  2016-05-28  Small unassuming place that changes their menu...   \n",
       "2      5  2016-05-28  Lester's is located in a beautiful neighborhoo...   \n",
       "3      4  2016-05-28  Love coming here. Yes the place always needs t...   \n",
       "4      4  2016-05-28  Had their chocolate almond croissant and it wa...   \n",
       "\n",
       "   useful  funny  cool  \n",
       "0       0      0     0  \n",
       "1       0      0     0  \n",
       "2       0      0     0  \n",
       "3       0      0     0  \n",
       "4       0      0     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FYWN1wneV18bWNgQjJ2GNg</td>\n",
       "      <td>\"Dental by Design\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"4855 E Warner Rd, Ste B9\"</td>\n",
       "      <td>Ahwatukee</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85044</td>\n",
       "      <td>33.330690</td>\n",
       "      <td>-111.978599</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>Dentists;General Dentistry;Health &amp; Medical;Or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He-G7vWjzVUysIKrfNbPUQ</td>\n",
       "      <td>\"Stephen Szabo Salon\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"3101 Washington Rd\"</td>\n",
       "      <td>McMurray</td>\n",
       "      <td>PA</td>\n",
       "      <td>15317</td>\n",
       "      <td>40.291685</td>\n",
       "      <td>-80.104900</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Hair Stylists;Hair Salons;Men's Hair Salons;Bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KQPW8lFf1y5BT2MxiSZ3QA</td>\n",
       "      <td>\"Western Motor Vehicle\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"6025 N 27th Ave, Ste 1\"</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85017</td>\n",
       "      <td>33.524903</td>\n",
       "      <td>-112.115310</td>\n",
       "      <td>1.5</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Departments of Motor Vehicles;Public Services ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8DShNS-LuFqpEWIp0HxijA</td>\n",
       "      <td>\"Sports Authority\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"5000 Arizona Mills Cr, Ste 435\"</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85282</td>\n",
       "      <td>33.383147</td>\n",
       "      <td>-111.964725</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Sporting Goods;Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PfOCPjBrlQAnz__NXj9h_w</td>\n",
       "      <td>\"Brick House Tavern + Tap\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"581 Howe Ave\"</td>\n",
       "      <td>Cuyahoga Falls</td>\n",
       "      <td>OH</td>\n",
       "      <td>44221</td>\n",
       "      <td>41.119535</td>\n",
       "      <td>-81.475690</td>\n",
       "      <td>3.5</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>American (New);Nightlife;Bars;Sandwiches;Ameri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                        name neighborhood  \\\n",
       "0  FYWN1wneV18bWNgQjJ2GNg          \"Dental by Design\"          NaN   \n",
       "1  He-G7vWjzVUysIKrfNbPUQ       \"Stephen Szabo Salon\"          NaN   \n",
       "2  KQPW8lFf1y5BT2MxiSZ3QA     \"Western Motor Vehicle\"          NaN   \n",
       "3  8DShNS-LuFqpEWIp0HxijA          \"Sports Authority\"          NaN   \n",
       "4  PfOCPjBrlQAnz__NXj9h_w  \"Brick House Tavern + Tap\"          NaN   \n",
       "\n",
       "                            address            city state postal_code  \\\n",
       "0        \"4855 E Warner Rd, Ste B9\"       Ahwatukee    AZ       85044   \n",
       "1              \"3101 Washington Rd\"        McMurray    PA       15317   \n",
       "2          \"6025 N 27th Ave, Ste 1\"         Phoenix    AZ       85017   \n",
       "3  \"5000 Arizona Mills Cr, Ste 435\"           Tempe    AZ       85282   \n",
       "4                    \"581 Howe Ave\"  Cuyahoga Falls    OH       44221   \n",
       "\n",
       "    latitude   longitude  stars  review_count  is_open  \\\n",
       "0  33.330690 -111.978599    4.0            22        1   \n",
       "1  40.291685  -80.104900    3.0            11        1   \n",
       "2  33.524903 -112.115310    1.5            18        1   \n",
       "3  33.383147 -111.964725    3.0             9        0   \n",
       "4  41.119535  -81.475690    3.5           116        1   \n",
       "\n",
       "                                          categories  \n",
       "0  Dentists;General Dentistry;Health & Medical;Or...  \n",
       "1  Hair Stylists;Hair Salons;Men's Hair Salons;Bl...  \n",
       "2  Departments of Motor Vehicles;Public Services ...  \n",
       "3                            Sporting Goods;Shopping  \n",
       "4  American (New);Nightlife;Bars;Sandwiches;Ameri...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a loop tp isolate the ratings and append it to a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting 40k of each review number and appending it to a new dataframe of 200k rows\n",
    "\n",
    "yelp_reviews_equal = pd.DataFrame()\n",
    "\n",
    "for x in range(6):\n",
    "    star_reviews = yelp_reviews.loc[(yelp_reviews['stars']== x)]\n",
    "    star_reviews = star_reviews.head(40000)\n",
    "    yelp_reviews_equal = yelp_reviews_equal.append(star_reviews)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    }
   ],
   "source": [
    "print(len(yelp_reviews_equal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                review_id                 user_id             business_id  \\\n",
      "0  vkVSCC7xljjrAI4UGfnKEQ  bv2nCi5Qv5vroFiqKGopiw  AEx2SYEUJmTxVVB18LlCwA   \n",
      "1  n6QzIUObkYshz4dz2QRJTw  bv2nCi5Qv5vroFiqKGopiw  VR6GpWIda3SfvPC-lg9H3w   \n",
      "2  MV3CcKScW05u5LVfF6ok0g  bv2nCi5Qv5vroFiqKGopiw  CKC0-MOWMqoeWf6s-szl8g   \n",
      "5  HRPm3vEZ_F-33TYVT7Pebw  _4iMDXbXZ1p1ONG297YEAQ  8QWPlVQ6D-OExqXoaD2Z1g   \n",
      "9  WF_QTN3p-thD74hqpp2j-Q  u0LXt3Uea_GidxRW1xcsfg  fDF_o2JPU8BR1Gya--jRIA   \n",
      "\n",
      "   stars        date                                               text  \\\n",
      "0      5  2016-05-28  Super simple place but amazing nonetheless. It...   \n",
      "1      5  2016-05-28  Small unassuming place that changes their menu...   \n",
      "2      5  2016-05-28  Lester's is located in a beautiful neighborhoo...   \n",
      "5      5  2014-09-24  Cycle Pub Las Vegas was a blast! Got a groupon...   \n",
      "9      5  2016-04-06  Love this place!\\n\\nPeggy is great with dogs a...   \n",
      "\n",
      "   useful  funny  cool  \n",
      "0       0      0     0  \n",
      "1       0      0     0  \n",
      "2       0      0     0  \n",
      "5       1      0     0  \n",
      "9       3      0     0  \n"
     ]
    }
   ],
   "source": [
    "#read review text reviews with only 5 star ratings for word cloud\n",
    "\n",
    "five_star_reviews = yelp_reviews.loc[(yelp_reviews['stars']==5)]\n",
    "five_star_reviews = five_star_reviews.head(40000)\n",
    "\n",
    "print(five_star_reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 review_id                 user_id             business_id  \\\n",
      "12  x5oV6wm9_Pb1QQ6jkjDjwQ  u0LXt3Uea_GidxRW1xcsfg  13nKUHH-uEUXVZylgxchPA   \n",
      "16  FKu4iU62EmWT6GZXPJ2sgA  u0LXt3Uea_GidxRW1xcsfg  fdnNZMk1NP7ZhL-YMidMpw   \n",
      "19  WYDFJOBOl7cycd7gN-c_xA  u0LXt3Uea_GidxRW1xcsfg  zgQHtqX0gqMw1nlBZl2VnQ   \n",
      "23  ypjtMQLKdAwKGRS-KU7oxA  u0LXt3Uea_GidxRW1xcsfg  hjk3ox7w1akbEuOgTJ03Bw   \n",
      "31  z9e32TaBomM5uY7fHYqYKg  u0LXt3Uea_GidxRW1xcsfg  I8rveLd-dl81u6c8YqAxmw   \n",
      "\n",
      "    stars        date                                               text  \\\n",
      "12      1  2011-02-16  I thought Tidy's Flowers had a great reputatio...   \n",
      "16      1  2012-10-23  I too have been trying to book an appt to use ...   \n",
      "19      1  2012-10-30  really excited to hear of this restaurant comi...   \n",
      "23      1  2012-05-10  Food is very bland - not authentic at all.\\n\\n...   \n",
      "31      1  2012-05-11  If you have not yet tried Wasabi - don't bothe...   \n",
      "\n",
      "    useful  funny  cool  \n",
      "12       9      0     1  \n",
      "16       0      0     0  \n",
      "19       9      2     1  \n",
      "23       4      2     0  \n",
      "31       3      0     0  \n",
      "1 Star Review Size 40000\n"
     ]
    }
   ],
   "source": [
    "#read review text reviews with only 1 star ratings for word cloud\n",
    "\n",
    "one_star_reviews = yelp_reviews.loc[(yelp_reviews['stars']==1)]\n",
    "one_star_reviews = one_star_reviews.head(40000)\n",
    "print(one_star_reviews.head())\n",
    "print(\"1 Star Review Size\", len(one_star_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  \\n#yelp_reviews_test = pd.read_csv(\"../Data/yelp_review.csv\", nrows = 10000) \\nwc_five_star_reviews = five_star_reviews.head(10000)\\n                                                                             \\ncomment_words = \\' \\'\\nstopwords = set(STOPWORDS) \\n# iterate through the csv file \\nfor val in wc_five_star_reviews.text: \\n      \\n    # typecaste each val to string \\n    val = str(val) \\n  \\n    # split the value \\n    tokens = val.split() \\n      \\n    # Converts each token into lowercase \\n    for i in range(len(tokens)): \\n        tokens[i] = tokens[i].lower() \\n          \\n    for words in tokens: \\n        comment_words = comment_words + words + \\' \\'\\n  \\n  \\nwordcloud = WordCloud(width = 800, height = 800, \\n                background_color =\\'white\\', \\n                stopwords = stopwords, \\n                min_font_size = 10,\\n                max_words = 100).generate(comment_words) \\n  \\n# plot the WordCloud image                        \\nplt.figure(figsize = (8, 8), facecolor = None) \\nplt.imshow(wordcloud) \\nplt.axis(\"off\") \\nplt.tight_layout(pad = 0) \\n  \\nplt.show()\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python program to generate WordCloud \n",
    "\n",
    "#word cloud for 10k of 5 star reviews\n",
    "'''  \n",
    "#yelp_reviews_test = pd.read_csv(\"../Data/yelp_review.csv\", nrows = 10000) \n",
    "wc_five_star_reviews = five_star_reviews.head(10000)\n",
    "                                                                             \n",
    "comment_words = ' '\n",
    "stopwords = set(STOPWORDS) \n",
    "# iterate through the csv file \n",
    "for val in wc_five_star_reviews.text: \n",
    "      \n",
    "    # typecaste each val to string \n",
    "    val = str(val) \n",
    "  \n",
    "    # split the value \n",
    "    tokens = val.split() \n",
    "      \n",
    "    # Converts each token into lowercase \n",
    "    for i in range(len(tokens)): \n",
    "        tokens[i] = tokens[i].lower() \n",
    "          \n",
    "    for words in tokens: \n",
    "        comment_words = comment_words + words + ' '\n",
    "  \n",
    "  \n",
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = stopwords, \n",
    "                min_font_size = 10,\n",
    "                max_words = 100).generate(comment_words) \n",
    "  \n",
    "# plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nwc_one_star_reviews = one_star_reviews.head(10000)\\n                                                                             \\ncomment_words = \\' \\'\\nstopwords = set(STOPWORDS) \\n# iterate through the csv file \\nfor val in wc_one_star_reviews.text: \\n      \\n    # typecaste each val to string \\n    val = str(val) \\n  \\n    # split the value \\n    tokens = val.split() \\n      \\n    # Converts each token into lowercase \\n    for i in range(len(tokens)): \\n        tokens[i] = tokens[i].lower() \\n          \\n    for words in tokens: \\n        comment_words = comment_words + words + \\' \\'\\n  \\n  \\nwordcloud = WordCloud(width = 800, height = 800, \\n                background_color =\\'white\\', \\n                stopwords = stopwords, \\n                min_font_size = 10,\\n                max_words = 100).generate(comment_words) \\n  \\n# plot the WordCloud image                        \\nplt.figure(figsize = (8, 8), facecolor = None) \\nplt.imshow(wordcloud) \\nplt.axis(\"off\") \\nplt.tight_layout(pad = 0) \\n  \\nplt.show()\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python program to generate WordCloud \n",
    "\n",
    "#word cloud for 10k of 1 star reviews\n",
    "''' \n",
    "wc_one_star_reviews = one_star_reviews.head(10000)\n",
    "                                                                             \n",
    "comment_words = ' '\n",
    "stopwords = set(STOPWORDS) \n",
    "# iterate through the csv file \n",
    "for val in wc_one_star_reviews.text: \n",
    "      \n",
    "    # typecaste each val to string \n",
    "    val = str(val) \n",
    "  \n",
    "    # split the value \n",
    "    tokens = val.split() \n",
    "      \n",
    "    # Converts each token into lowercase \n",
    "    for i in range(len(tokens)): \n",
    "        tokens[i] = tokens[i].lower() \n",
    "          \n",
    "    for words in tokens: \n",
    "        comment_words = comment_words + words + ' '\n",
    "  \n",
    "  \n",
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = stopwords, \n",
    "                min_font_size = 10,\n",
    "                max_words = 100).generate(comment_words) \n",
    "  \n",
    "# plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    I thought Tidy's Flowers had a great reputatio...\n",
       "16    I too have been trying to book an appt to use ...\n",
       "19    really excited to hear of this restaurant comi...\n",
       "23    Food is very bland - not authentic at all.\\n\\n...\n",
       "31    If you have not yet tried Wasabi - don't bothe...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews_equal.text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing punctuation from the reviews\n",
    "#****use the same dataframe, take things out of memory**\n",
    "yelp_reviews_equal['cleaned_text'] = yelp_reviews_equal['text'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the review text all lowercase\n",
    "yelp_reviews_equal['cleaned_text'] = yelp_reviews_equal['cleaned_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all numbers from reviews\n",
    "yelp_reviews_equal['cleaned_text'] = yelp_reviews_equal['cleaned_text'].str.replace(r'\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing _ (underscores) from the review text\n",
    "yelp_reviews_equal['cleaned_text'] = yelp_reviews_equal['cleaned_text'].str.replace('_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting each word into a list\n",
    "yelp_reviews_equal['cleaned_text'] = yelp_reviews_equal['cleaned_text'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    [i, thought, tidys, flowers, had, a, great, re...\n",
       "16    [i, too, have, been, trying, to, book, an, app...\n",
       "19    [really, excited, to, hear, of, this, restaura...\n",
       "23    [food, is, very, bland, not, authentic, at, al...\n",
       "31    [if, you, have, not, yet, tried, wasabi, dont,...\n",
       "Name: cleaned_text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews_equal['cleaned_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all stop words (and, but, then, etc)\n",
    "stop = stopwords.words('english')\n",
    "yelp_reviews_equal['cleaned_text'] = yelp_reviews_equal['cleaned_text'].apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemmer = SnowballStemmer(\"english\")\n",
    "#yelp_reviews['cleaned_text'] = stop_words.apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatize the text and take it out of the list\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "yelp_reviews_equal['cleaned_text'] = yelp_reviews_equal['cleaned_text'].apply(lambda x:' '.join([lemmatizer.lemmatize(y) for y in x])) # Lemmatize every word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    thought tidy flower great reputation florist g...\n",
       "16    trying book appt use voucher month countless p...\n",
       "19    really excited hear restaurant coming toronto ...\n",
       "23    food bland authentic meant cater customer neve...\n",
       "31    yet tried wasabi dont bother expensive food di...\n",
       "Name: cleaned_text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews_equal['cleaned_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>x5oV6wm9_Pb1QQ6jkjDjwQ</td>\n",
       "      <td>u0LXt3Uea_GidxRW1xcsfg</td>\n",
       "      <td>13nKUHH-uEUXVZylgxchPA</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-02-16</td>\n",
       "      <td>I thought Tidy's Flowers had a great reputatio...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>thought tidy flower great reputation florist g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FKu4iU62EmWT6GZXPJ2sgA</td>\n",
       "      <td>u0LXt3Uea_GidxRW1xcsfg</td>\n",
       "      <td>fdnNZMk1NP7ZhL-YMidMpw</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-10-23</td>\n",
       "      <td>I too have been trying to book an appt to use ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>trying book appt use voucher month countless p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>WYDFJOBOl7cycd7gN-c_xA</td>\n",
       "      <td>u0LXt3Uea_GidxRW1xcsfg</td>\n",
       "      <td>zgQHtqX0gqMw1nlBZl2VnQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-10-30</td>\n",
       "      <td>really excited to hear of this restaurant comi...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>really excited hear restaurant coming toronto ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ypjtMQLKdAwKGRS-KU7oxA</td>\n",
       "      <td>u0LXt3Uea_GidxRW1xcsfg</td>\n",
       "      <td>hjk3ox7w1akbEuOgTJ03Bw</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-05-10</td>\n",
       "      <td>Food is very bland - not authentic at all.\\n\\n...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>food bland authentic meant cater customer neve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>z9e32TaBomM5uY7fHYqYKg</td>\n",
       "      <td>u0LXt3Uea_GidxRW1xcsfg</td>\n",
       "      <td>I8rveLd-dl81u6c8YqAxmw</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-05-11</td>\n",
       "      <td>If you have not yet tried Wasabi - don't bothe...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yet tried wasabi dont bother expensive food di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 review_id                 user_id             business_id  \\\n",
       "12  x5oV6wm9_Pb1QQ6jkjDjwQ  u0LXt3Uea_GidxRW1xcsfg  13nKUHH-uEUXVZylgxchPA   \n",
       "16  FKu4iU62EmWT6GZXPJ2sgA  u0LXt3Uea_GidxRW1xcsfg  fdnNZMk1NP7ZhL-YMidMpw   \n",
       "19  WYDFJOBOl7cycd7gN-c_xA  u0LXt3Uea_GidxRW1xcsfg  zgQHtqX0gqMw1nlBZl2VnQ   \n",
       "23  ypjtMQLKdAwKGRS-KU7oxA  u0LXt3Uea_GidxRW1xcsfg  hjk3ox7w1akbEuOgTJ03Bw   \n",
       "31  z9e32TaBomM5uY7fHYqYKg  u0LXt3Uea_GidxRW1xcsfg  I8rveLd-dl81u6c8YqAxmw   \n",
       "\n",
       "    stars        date                                               text  \\\n",
       "12      1  2011-02-16  I thought Tidy's Flowers had a great reputatio...   \n",
       "16      1  2012-10-23  I too have been trying to book an appt to use ...   \n",
       "19      1  2012-10-30  really excited to hear of this restaurant comi...   \n",
       "23      1  2012-05-10  Food is very bland - not authentic at all.\\n\\n...   \n",
       "31      1  2012-05-11  If you have not yet tried Wasabi - don't bothe...   \n",
       "\n",
       "    useful  funny  cool                                       cleaned_text  \n",
       "12       9      0     1  thought tidy flower great reputation florist g...  \n",
       "16       0      0     0  trying book appt use voucher month countless p...  \n",
       "19       9      2     1  really excited hear restaurant coming toronto ...  \n",
       "23       4      2     0  food bland authentic meant cater customer neve...  \n",
       "31       3      0     0  yet tried wasabi dont bother expensive food di...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews_equal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id       0\n",
       "user_id         0\n",
       "business_id     0\n",
       "stars           0\n",
       "date            0\n",
       "text            0\n",
       "useful          0\n",
       "funny           0\n",
       "cool            0\n",
       "cleaned_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for null values\n",
    "yelp_reviews_equal.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a new dataframe with less rows for the sake of machine learning\n",
    "\n",
    "yelp_reviews_ml = pd.DataFrame()\n",
    "\n",
    "for x in range(6):\n",
    "    ml_reviews = yelp_reviews_equal.loc[(yelp_reviews_equal['stars']== x)]\n",
    "    ml_reviews = ml_reviews.head(8000)\n",
    "    yelp_reviews_ml = yelp_reviews_ml.append(ml_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n"
     ]
    }
   ],
   "source": [
    "print(len(yelp_reviews_ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_data = yelp_reviews_ml['cleaned_text']\n",
    "text_data = yelp_reviews_equal['cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'aaa', 'aaaaa', 'aaaaaaaaaaaaahhhhhhh', 'aaaaaaaaaaand', 'aaaaaaaaand', 'aaaaaaaannnnd', 'aaaaaaahhhhhh', 'aaaaaaall', 'aaaaaaand']\n",
      "(200000, 179642)\n"
     ]
    }
   ],
   "source": [
    "#use tokenizer as an argument, get feautre names, n-gram range =  1\n",
    "\n",
    "#Use count vect\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(text_data)\n",
    "print(count_vect.get_feature_names()[:10])\n",
    "print(X_train_counts.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 175443)\t0.11314975513813419\n",
      "  (0, 171108)\t0.042019394632723105\n",
      "  (0, 166709)\t0.1269287108242341\n",
      "  (0, 166398)\t0.401122238258285\n",
      "  (0, 163879)\t0.09009799926959466\n",
      "  (0, 157729)\t0.22141184527945038\n",
      "  (0, 157233)\t0.05125915925632052\n",
      "  (0, 152923)\t0.043660741892785175\n",
      "  (0, 151874)\t0.07356286020695979\n",
      "  (0, 148607)\t0.1144442462894998\n",
      "  (0, 145917)\t0.08363099777705771\n",
      "  (0, 143081)\t0.04713827831253366\n",
      "  (0, 141520)\t0.07363010971996788\n",
      "  (0, 140631)\t0.13718243895572493\n",
      "  (0, 140407)\t0.06213518971378355\n",
      "  (0, 133277)\t0.0431354466707839\n",
      "  (0, 131830)\t0.37244374484610826\n",
      "  (0, 128704)\t0.1343090840663717\n",
      "  (0, 128549)\t0.09547402898999534\n",
      "  (0, 126219)\t0.062233923336311156\n",
      "  (0, 125860)\t0.03433340456276769\n",
      "  (0, 117637)\t0.07409154947922272\n",
      "  (0, 117602)\t0.026254280114515638\n",
      "  (0, 110404)\t0.12565758060211515\n",
      "  (0, 109986)\t0.11738736588006041\n",
      "  :\t:\n",
      "  (0, 68878)\t0.06785180003130808\n",
      "  (0, 68874)\t0.07396525333759649\n",
      "  (0, 68644)\t0.08980624572821076\n",
      "  (0, 67087)\t0.05863729192359485\n",
      "  (0, 66072)\t0.06222089023365212\n",
      "  (0, 65866)\t0.03111450587983534\n",
      "  (0, 62804)\t0.11626253447373278\n",
      "  (0, 59368)\t0.09169930906644015\n",
      "  (0, 57028)\t0.366078262928383\n",
      "  (0, 56981)\t0.3583957264652843\n",
      "  (0, 55072)\t0.1176843642980271\n",
      "  (0, 52213)\t0.06309848439599416\n",
      "  (0, 44691)\t0.08157883240304901\n",
      "  (0, 41232)\t0.0379550333977746\n",
      "  (0, 39629)\t0.07517493233701854\n",
      "  (0, 39625)\t0.08130361064937588\n",
      "  (0, 38084)\t0.20781919926265066\n",
      "  (0, 36994)\t0.06096137070209393\n",
      "  (0, 32480)\t0.09177991916723019\n",
      "  (0, 31884)\t0.06615963828201991\n",
      "  (0, 26251)\t0.06783988333098617\n",
      "  (0, 23061)\t0.1041646127497836\n",
      "  (0, 21730)\t0.10903665022799683\n",
      "  (0, 18874)\t0.06910505919350492\n",
      "  (0, 1215)\t0.05137764777516597\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "#vec.fit(yelp_reviews.cleaned_text)\n",
    "vec.fit(yelp_reviews_equal.cleaned_text.values.astype('U'))\n",
    "features = vec.transform(yelp_reviews_equal.cleaned_text)\n",
    "\n",
    "print(features[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(features.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              stars        useful        funny          cool\n",
      "count  40000.000000  40000.000000  40000.00000  40000.000000\n",
      "mean       3.000000      1.661900      0.64155      0.628100\n",
      "std        1.414231      8.091003      3.02449      2.490842\n",
      "min        1.000000      0.000000      0.00000      0.000000\n",
      "25%        2.000000      0.000000      0.00000      0.000000\n",
      "50%        3.000000      1.000000      0.00000      0.000000\n",
      "75%        4.000000      2.000000      1.00000      1.000000\n",
      "max        5.000000   1456.000000    447.00000    245.000000\n"
     ]
    }
   ],
   "source": [
    "print(yelp_reviews_ml.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 69319)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vect.fit_transform(yelp_reviews_ml.cleaned_text)\n",
    "print(X_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'aaa', 'aaaaa', 'aaaaaaaaaaaaahhhhhhh', 'aaaaaaall', 'aaaaahhhmaizeing', 'aaaaand', 'aaaahhhh', 'aaaand', 'aaahhh']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vect.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test train split, use train in validation, fit model.\n",
    "#best practice: apply best parameters on the 20% of validation test and compare accuracy\n",
    "#applied before fitting (**train_test_split**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_counts\n",
    "y = yelp_reviews_equal.stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.80,test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest for the test model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [1,10,100],\n",
    "        'max_depth': [1,10],\n",
    "        'min_samples_leaf': [100]}\n",
    "gs = GridSearchCV(rf, param, cv=5)\n",
    "gs_fit = gs.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'min_samples_leaf': 100, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "best_params = gs_fit.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45630625\n"
     ]
    }
   ],
   "source": [
    "print(gs_fit.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = gs_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 2 5 ... 3 5 1]\n"
     ]
    }
   ],
   "source": [
    "print(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting it on test set\n",
    "#y_pred = clf_fit.predict(X_test)\n",
    "#mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try grid searching on the 80%\n",
    "#with the 20% use the best parameters to fit on it --> confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy\n",
    "#false positives and negatives (classification - confusion matrix) * maximize the diagonal\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#google colabs (google cloud), run this on kaggle?\n",
    "#https://colab.research.google.com/notebooks/intro.ipynb\n",
    "#put a log on the grid search, to see how long it computes/what takes so long\n",
    "#try one or two\n",
    "\n",
    "#clf.grid_scores_\n",
    "#https://stackoverflow.com/questions/22155953/how-to-print-out-an-accuracy-score-for-each-combination-within-gridsearch\n",
    "\n",
    "#let things run for an hour\n",
    "\n",
    "#reduce the columns/rows for the machine learning part 20k rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification matrix - false positive and negatives\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
